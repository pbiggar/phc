%%
% Authors:
%   Brian Hackett  <bhackett@stanford.edu>
%
% Copyright (c) 2006,
%   The Board of Trustees of The Leland Stanford Junior University
% All rights reserved.
%
% Redistribution and use in source and binary forms, with or without
% modification, are permitted provided that the following conditions are met:
% 
% 1. Redistributions of source code must retain the above copyright notice,
% this list of conditions and the following disclaimer.
% 
% 2. Redistributions in binary form must reproduce the above copyright notice,
% this list of conditions and the following disclaimer in the documentation
% and/or other materials provided with the distribution.
% 
% 3. The names of the contributors may not be used to endorse or promote
% products derived from this software without specific prior written
% permission.
% 
% THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
% AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
% IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
% ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
% LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
% CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
% SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
% INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
% CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
% ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
% POSSIBILITY OF SUCH DAMAGE.
%%

% Path-sensitive intraprocedural points-to and value-aliasing information.
% If the alias analysis has not already been run, assumes non-aliasing at
% entry and side-effect free callees

% this file leaves the type t_nrep of intermediate int/float values abstract.
% files importing this which need to manipulate such values must define t_nrep
type t_nrep.

import "traces.clp".
import "paths.clp".

% PREDICATES

% pointers are normally assumed to be non-aliased at entry, that the targets of
% two different traces are themselves two different traces. any extra points-to
% information in the sum_entry, sum_exit, and other summaries from traces.clp
% are used to relax this assumption

% possible values a trace can hold
type t_trace_val ::=
    trace{t_trace}  % address of another trace (points-to relationship)
  | nrep{t_nrep}.   % intermediate integer/float result

% integer values are abstracted here as the t_nrep type. to model integers,
% an additional file such as scalar.clp, intbvec.clp or intignore.clp must be
% imported, which generates new intermediate integer values

% note that all per-pp guards, i.e. val, eval, lval, inst_trace, etc.
% are dependent on P actually being reachable, guard(P,G). to get the conds
% under which both P is reachable *AND* a property val(P,S,T,_) holds, conjoin
% guard(P,GG) and val(P,S,T,G).

% at program point P, the memory location with canonical name S contains value 
% T when G holds (if S is a pointer, then S points to T). Note that S must be 
% the canonical name for the location -- this predicate does NOT work for
% arbitrary access paths.
predicate val(in P:pp,in S:t_trace,T:t_trace_val,G:g_guard).

% at program point P, expression E points to T if G holds.
predicate eval(in P:pp,in E:c_exp,T:t_trace_val,G:g_guard).

% at program point P, lval LV refers to trace T if G holds
predicate lval(in P:pp,in LV:c_lval,T:t_trace,G:g_guard).

% as interpreted by the call/loop SUM at point P, trace CT maps to T if G holds
predicate inst_trace(in SUM:sum,in P:pp,in CT:t_trace,T:t_trace_val,G:g_guard).

% top-down inst_trace; caller trace T is mapped to by trace CT if G holds
predicate td_inst_trace(in SUM:sum,in P:pp,in T:t_trace,CT:t_trace,G:g_guard).

% val() summary transfer function. S has value T if G holds after transfer
% over the call/loop at P
predicate inst_transfer(in P:pp,in S:t_trace,T:t_trace_val,G:g_guard).

% T is directly accessed at program point P as a read or write (not deepwrite).
% accesses through callees are not included here.
predicate access(P:pp,T:t_trace,access_type).

% 'relevant' inst_trace generated only for caller traces that were accessed
% directly by this function. used as the basis for td_inst_trace
predicate rel_inst_trace(I:sum,P:pp,CT:t_trace,T:t_trace,G:g_guard).

% SESSIONS

% summary cacheing the bottom-up portions of the memory analysis.
% evaluates every expression 
session memory_cache(FN:string,SUM:sum)
    containing [eval,lval,rel_inst_trace,
                inst_exit_points,inst_usemod,inst_anyuse,
                split_transfer_necessary,split_transfer_write].

% add memory predicates generated by this analysis to the summary cache
predicate add_memory_cache().

% pull in cached memory predicates, disable eager local re-evaluation of them
predicate use_memory_cache().

% INDEX PREDICATES

% generate index traces rather than smashing arrays/structures together
predicate generate_index_traces().

% ways to move from one index within a structure to another
type t_trace_one_index ::=
      % take offset V by element width of Y
    i_offset{Y:t_type,V:t_trace_val}
      % follow accesses RT to get an adjacent element
  | i_next{RT:t_trace}
      % result of SUM performing a chain of accesses on T,
      % writing the result to S
  | i_chain{P:pp,S:t_trace,T:t_trace}
  .
type t_trace_index = list[t_trace_one_index].

% takes index I of T, adding it to any existing index at the head of T
% and simplifying the result as much as possible
predicate trace_add_index(in T:t_trace,in I:t_trace_one_index,NT:t_trace)
    succeeds [once].

% as with trace_simplify, but if the simplification removes any recursion
% then it will be reflected within an index{} on NT.
% identical to trace_simplify if generate_index_traces() not specified
predicate trace_simplify_index(in SUM:sum,in OT:t_trace,NT:t_trace)
    succeeds [once].

% INTEGER PREDICATES

% these must be supplied by any integer or other analysis incorporating
% this file

% get an unconstrained bit to distinguish the condition under which
% S points to T at entry point P or as side effect to SUM.
% must be provided once the type of g_bit is actually known
predicate entry_bit(in P:pp,in S:t_trace,in T:t_trace,BG:g_guard)
    succeeds [once].
predicate exit_bit(in SUM:sum,in P:pp,in CS:t_trace,in CT:t_trace,BG:g_guard)
    succeeds [once].

% get the particular scalar value of a trace_val under an assignment
% generated by guard_sat_asn
predicate asn_value(in ASN:g_guard_asn,in NR:t_trace_val,N:int)
    succeeds [once].

% as interpreted by call/loop SUM at point P, CV maps to V if G holds
predicate inst_trace_val(in SUM:sum,in P:pp,in CV:t_trace_val,
                         V:t_trace_val,G:g_guard).
predicate td_inst_trace_val(in SUM:sum,in P:pp,in V:t_trace_val,
                            CV:t_trace_val,G:g_guard).

% get the unconstrained nrep/guard result of evaluating E at P,
% to be used if the above nrep_* are not defined. must be defined for all E/P
% unless the expression can be completely modelled as nreps
predicate unconstrained_nrep(in P:pp,in E:c_exp,V:t_nrep) succeeds [once].
predicate unconstrained_cond(in P:pp,in E:c_exp,G:g_guard) succeeds [once].

% convert trace values to nreps. may be left undefined, in which case
% an unconstrained value will be used
predicate trace_nrep(in V:t_trace_val,NV:t_nrep).

% convert trace values to nreps as the result of evaluation of E at P.
% always succeeds, and may coerce the nrep to the type of E if the two differ.
% by default this is implemented in terms of trace_nrep
% and unconstrained_nrep used when trace_nrep fails, but may be overridden with
% omit_trace_nrep_exp
predicate trace_nrep_exp(in P:pp,in E:c_exp,in V:t_trace_val,NV:t_nrep)
    succeeds [once].
predicate omit_trace_nrep_exp().

% flatten a set of nreps with disjoint guards attached into a single nrep.
% may be left undefined, in which case expressions will be separately evaluated
% for each trace their lvalue subexpressions could reference
predicate nrep_flatten(in VLIST:list[t_pair[t_nrep,g_guard]],V:t_nrep).

% get the sign/length of an nrep
predicate nrep_bits(in V:t_nrep,SIGN:bool,LEN:int) succeeds [once].

% arithmetic operations on nreps. any of these may be undefined,
% in which case an unconstrained value will be used
predicate nrep_const_int(in K:ikind,in N:int,NV:t_nrep).
predicate nrep_const_flt(in K:fkind,in N:float,NV:t_nrep).
predicate nrep_cast(in SIGN:bool,in LEN:int,in V:t_nrep,NV:t_nrep).
predicate nrep_unop(in U:unop,in V:t_nrep,NV:t_nrep).
predicate nrep_binop(in B:binop,in LV:t_nrep,in RV:t_nrep,NV:t_nrep).
predicate nrep_nez(in V:t_nrep,G:g_guard).
predicate nrep_cmp(in B:binop,in LV:t_nrep,in RV:t_nrep,G:g_guard).

% get the plain output string for an nrep
predicate nrep_string(in V:t_nrep,STR:string) succeeds [once].

% get the UI string for an nrep
predicate dstring_nrep(in SUM:sum,in V:t_nrep,STR:string) succeeds [once].

% extensions of nrep_const_int and nrep_binop for use in working with indexes.
% these behave similarly except they are required to succeed
predicate trace_val_const_int(in K:ikind,in N:int,V:t_trace_val)
    succeeds [once].
predicate trace_val_binop(in OP:binop,in LV:t_trace_val,in RV:t_trace_val,
                          NV:t_trace_val)
    succeeds [once].

trace_val_const_int(K,N,nrep{V}) :- nrep_const_int(K,N,V).
trace_val_binop(OP,XLV,XRV,nrep{V}) :-
    trace_nrep(XLV,LV), trace_nrep(XRV,RV), nrep_binop(OP,LV,RV,V).

% SUMMARY TRANSFER PREDICATES

% G is a necessary condition for the target of S to be preserved across the
% call/loop SUM at P
predicate inst_transfer_necessary(in SUM:sum,in P:pp,in S:t_trace,G:g_guard).

% the call/loop at P may write S with unconstrained offset I into trace T.
% if not specified then nrep_const_int(0) will be used
predicate inst_write_array(in P:pp,in S:t_trace,in T:t_trace,I:t_trace_val).

% the call/loop SUM at P may write S with unconstrained integer V.
% if not specified then the value of S before the call will be used
predicate inst_write_int(in P:pp,in S:t_trace,V:t_trace_val).

% CUSTOMIZATION

% val() will not be computed anywhere - disables memory analysis
predicate disable_val().

% aliasing information from sum_entry will not be used for SUM
predicate omit_entry_alias_summary(in SUM:sum).

% aliasing information from sum_exit/sum_usemod will not be used for SUM
predicate omit_exit_alias_summary(in SUM:sum).

% the entry relationship S->T on SUM will not be generated
predicate omit_entry_points(in SUM:sum,in S:t_trace,in T:t_trace).

% the side effect S->T on SUM will not be generated
predicate omit_exit_points(in SUM:sum,in S:t_trace,in T:t_trace).

% entry aliases are not used to relax the entry points-to graph
predicate no_entry_aliasing().

% ignore side effects on SUM at P
predicate no_exit_aliasing(in SUM:sum,in P:pp).

% do not attempt to apply integer or index side effects on T at P/SUM
predicate no_inst_may_write(in SUM:sum,in P:pp,in T:t_trace).

% prevent lval(P,LV,_,_) from being computed in the standard way,
% allowing for customization of lval(P,LV,_,_)
predicate omit_lval(in P:pp,in LV:c_lval).

% prevent eval(P,E,_,_) from being computed in the standard way,
% allowing for customization of eval(P,E,_,_)
predicate omit_eval(in P:pp,in E:c_exp).

% modify eval() to ignore casts between or in/out of integer types.
% these are needed to model any sign changes etc. that could occur but also
% mask the flow of pointers that are masquarading as integers
predicate ignore_int_casts().

% S may be written 
predicate call_effect(in SUM:sum,in P:pp,in S:t_trace).

% only generate inst_trace for arguments included in the function prototype
predicate matching_arg_inst_trace().

% do not generate rel_inst_trace
predicate no_rel_inst_trace().

% RULES

% if we are adding to the memory cache, fill in data for P to FN/SUM
predicate add_cache_sum(P:pp,FN:string,SUM:sum).
add_memory_cache(), cil_curfn(FN), sum_body(SUM,P),
    +add_cache_sum(P,FN,SUM).

% if we are using the memory cache, pull in data from FN/SUM
predicate use_cache_sum(FN:string,SUM:sum).
use_memory_cache(), cil_curfn(FN), sum_bound(SUM,_,_),
    +use_cache_sum(FN,SUM).

% CIL location offsets

% CIL offset OFF of root trace RT as calculated at P is T if G holds
predicate trace_offset(in P:pp,in RT:t_trace,in OFF:c_offset,
                       T:t_trace,G:g_guard).

% empty offsets preserve the original location
#bool_g(true,G), cil_off_none(OFF), +trace_offset(_,RT,OFF,RT,G).

% field offsets take the specified field of the original location
cil_off_field(OFF,FX,NOFF), cil_field_name(FX,F,_,_,_),
    base_off_type(OFF,TYP), cil_type_comp(TYP,C),
    ?trace_offset(P,RT,OFF,_,_), sum_body(SUM,P),
    trace_simplify_index(SUM,fld{RT,F,C},FT),
    trace_offset(P,FT,NOFF,T,G), +trace_offset(P,RT,OFF,T,G).

% index offsets are handled only if generate_index_traces() is being used,
% otherwise ignored and preserving the original location
~generate_index_traces(), cil_off_index(OFF,_,NOFF),
    ?trace_offset(P,RT,OFF,_,_), trace_offset(P,RT,NOFF,T,G),
    +trace_offset(P,RT,OFF,T,G).
generate_index_traces(), cil_off_index(OFF,E,NOFF),
    ?trace_offset(P,RT,OFF,_,_), eval(P,E,I,IG),
    base_off_type(NOFF,ETYP), convert_type(ETYP,EY),
    trace_add_index(RT,i_offset{EY,I},IT),
    trace_offset(P,IT,NOFF,T,TG), #and(IG,TG,G), ~#bool_g(false,G),
    +trace_offset(P,RT,OFF,T,G).

% reverse RT to T such that trace_offset(P,T,OFF,RT,G).
predicate trace_rev_offset(in P:pp,in RT:t_trace,in OFF:c_offset,T:t_trace,G:g_guard).
#bool_g(true,G), cil_off_none(OFF), +trace_rev_offset(_,RT,OFF,RT,G).
cil_off_field(OFF,FX,NOFF), cil_field_name(FX,F,_,_,_),
    base_off_type(OFF,TYP), cil_type_comp(TYP,C),
    ?trace_rev_offset(P,RT,OFF,_,_), trace_rev_offset(P,RT,NOFF,MT,G),
    trace_simplify_index(s_func,rfld{MT,F,C},T),
    +trace_rev_offset(P,RT,OFF,T,G).
~generate_index_traces(), cil_off_index(OFF,_,NOFF),
    ?trace_rev_offset(P,RT,OFF,_,_),
    trace_rev_offset(P,RT,NOFF,T,G), +trace_rev_offset(P,RT,OFF,T,G).
generate_index_traces(), cil_off_index(OFF,E,NOFF),
    ?trace_rev_offset(P,RT,OFF,_,_), eval(P,E,I,IG),
    base_off_type(NOFF,ETYP), convert_type(ETYP,EY),
    trace_val_const_int(iint,-1,N1), trace_val_binop(b_mult,I,N1,NI),
    trace_rev_offset(P,RT,NOFF,MT,TG), #and(IG,TG,G), ~#bool_g(false,G),
    trace_add_index(MT,i_offset{EY,NI},T), +trace_rev_offset(P,RT,OFF,T,G).

% get a fixed number of bytes represented by an offset
predicate offset_bytes(in OFF:c_offset,N:int).
cil_off_none(OFF), +offset_bytes(OFF,0).
cil_off_field(OFF,FX,NOFF), cil_field_name(FX,_,_,BBS,_), int_div(BBS,8,BS),
    ?offset_bytes(OFF,_), offset_bytes(NOFF,NN), int_add(BS,NN,N),
    +offset_bytes(OFF,N).
cil_off_index(OFF,_,_), ?offset_bytes(OFF,_),
    +warning("Can't compute offset_bytes for index trace").

% pointer casts

% casting T to type Y yields CT. not be defined for all T
predicate trace_val_cast(in SUM:sum,in T:t_trace_val,in Y:t_type,
                         CT:t_trace_val).

predicate fld_chain(in SUM:sum,in T:t_trace,in FLIST:list[t_pair[string,string]],NT:t_trace).
+fld_chain(_,T,[],T).
fld_chain(SUM,T,[pair{F,C}|FLIST],NT) :-
    trace_simplify(SUM,fld{T,F,C},MT), fld_chain(SUM,MT,FLIST,NT).

predicate rfld_chain(in SUM:sum,in T:t_trace,in FLIST:list[t_pair[string,string]],NT:t_trace).
+rfld_chain(_,T,[],T).
rfld_chain(SUM,T,[pair{F,C}|FLIST],NT) :-
    rfld_chain(SUM,T,FLIST,MT), trace_simplify(SUM,rfld{MT,F,C},NT).

% look for field upcasts, where a pointer to some comp C is cast to the type of
% one of its first fields, or downcasts, where a pointer to some type Y is
% cast to a type which contains Y as its first field
predicate field_cast(in SUM:sum,in T:t_trace,in Y:t_type,NT:t_trace).
field_cast(SUM,T,Y,NT) :- Y\=y_int{_}, trace_type(SUM,T,y_comp{C}),
    first_field(C,Y,FLIST), fld_chain(SUM,T,FLIST,NT).
field_cast(SUM,T,y_comp{C},NT) :- trace_type(SUM,T,Y), Y\=y_int{_},
    first_field(C,Y,FLIST), rfld_chain(SUM,T,FLIST,NT).

% apply field_cast where possible, otherwise preserve the trace
trace_val_cast(SUM,trace{T},Y,trace{NT}) :- field_cast(SUM,T,Y,NT).
trace_val_cast(SUM,trace{T},Y,trace{T}) :- ~field_cast(SUM,T,Y,_).
+trace_val_cast(_,nrep{V},_,nrep{V}).

% lvalue evaluation

% add/use lval valuation for the corresponding point to the memory cache
add_cache_sum(P,FN,SUM), lval_point(LV,P), lval(P,LV,T,G),
    +memory_cache(FN,SUM)->lval(P,LV,T,G).
use_cache_sum(FN,SUM), lval_point(LV,P),
    memory_cache(FN,SUM)->lval(P,LV,T,G),
    +omit_lval(P,LV), +lval(P,LV,T,G).

% compute the trace for variable lvals. this is an offset from the var_trace
% for the variable, which may itself be a recursive cell if the head element
% is a stack- or statically-allocated structure
cil_lval_var(LV,X,OFF), var_trace(X,R), ?lval(P,LV,_,_), ~omit_lval(P,LV),
    sum_body(SUM,P), trace_simplify_index(SUM,root{R},RT),
    trace_offset(P,RT,OFF,T,G), +lval(P,LV,T,G).

% compute the trace for memory lvals. evaluate the pointer for its targets,
% then take the offset of each target
cil_lval_mem(LV,ME,OFF), ?lval(P,LV,_,_), ~omit_lval(P,LV),
    eval(P,ME,trace{RT},MG), trace_offset(P,RT,OFF,T,OG),
    #and(MG,OG,G), ~#bool_g(false,G), +lval(P,LV,T,G).

% constructing indexes

% cast an index BI of elem width BBS to index NI of elem width NBS,
% scaling scaling BI as appropriate. we currently only support clean
% multiplication/division of sizes
predicate index_cast(in BI:t_trace_val,in BBS:int,in NBS:int,NI:t_trace_val).
+index_cast(I,BS,BS,I).
index_cast(BI,BBS,NBS,NI) :- int_gt(BBS,NBS),
    int_div(BBS,NBS,DN), int_mul(DN,NBS,BBS),
    trace_val_const_int(iint,DN,DNV), trace_val_binop(b_mult,BI,DNV,NI).
index_cast(BI,BBS,NBS,NI) :- int_lt(BBS,NBS),
    int_div(NBS,BBS,DN), int_mul(DN,BBS,NBS),
    trace_val_const_int(iint,DN,DNV), trace_val_binop(b_div,BI,DNV,NI).

trace_add_index(T,I,index{T,[I]}) :- T\=index{_,_}.
trace_add_index(index{T,BI},I,index{T,[I|BI]}) :-
    (I\=i_offset{_,_}; BI\=[i_offset{_,_}|_]).
trace_add_index(index{T,BI},I,index{T,NI}) :-
    I=i_offset{Y,V}, BI=[i_offset{XY,XV}|BBI],
    type_width(XY,XBS), type_width(Y,BS),
    (index_cast(XV,XBS,BS,AV), trace_val_binop(b_plusa,V,AV,NV),
         NI=[i_offset{Y,NV}|BBI];
     ~index_cast(XV,XBS,BS,_), NI=[i_offset{Y,V},i_offset{XY,XV}|BBI]).

% simplify recursive structures, preserving any removed recursion as indexes
~generate_index_traces(), ?trace_simplify_index(I,OT,_),
    trace_simplify(I,OT,NT), +trace_simplify_index(I,OT,NT).
generate_index_traces(), ?trace_simplify_index(I,OT,_),
    trace_simplify(I,OT,OT), +trace_simplify_index(I,OT,OT).
generate_index_traces(), ?trace_simplify_index(I,OT,_),
    trace_simplify(I,OT,NT), NT\=OT,
    trace_sub(OT,NT,BRT), trace_strip_index(BRT,RT),
    trace_simplify(s_func,RT,NRT),  % remove rfld{fld{empty,F},F} etc.
    (NRT=empty, NNT=NT;
     NRT\=empty, trace_add_index(NT,i_next{NRT},NNT)),
    +trace_simplify_index(I,OT,NNT).

% constructing expression nreps

% E at P evaluates to the integer value V if G holds. will flatten results
% if possible, useful for expression evaluation that requires a non-zero value
predicate eval_nrep(in P:pp,in E:c_exp,V:t_nrep,G:g_guard).

~omit_trace_nrep_exp(), ?trace_nrep_exp(P,E,V,_),
    (trace_nrep(V,NV); ~trace_nrep(V,_), unconstrained_nrep(P,E,NV)),
    nrep_bits(NV,S,LEN), exp_type(E,ETYP), type_bits(ETYP,ES,ELEN),
    (pair{S,LEN}=pair{ES,ELEN}, NNV=NV;
     pair{S,LEN}\=pair{ES,ELEN}, nrep_cast(ES,ELEN,NV,NNV);
     pair{S,LEN}\=pair{ES,ELEN}, ~nrep_cast(ES,ELEN,NV,_), unconstrained_nrep(P,E,NNV)),
    +trace_nrep_exp(P,E,V,NNV).

?eval_nrep(P,E,_,_),
     \/(eval(P,E,XV,XG), trace_nrep_exp(P,E,XV,NXV)):list_all(pair{NXV,XG},VL),
     (VL=[], unconstrained_nrep(P,E,V), #bool_g(true,G);
      VL=[pair{V,G}];
      VL\=[], VL\=[_], nrep_flatten(VL,V), #bool_g(true,G);
      VL\=[], VL\=[_], ~nrep_flatten(VL,_), list_mem(VL,pair{V,G})),
     +eval_nrep(P,E,V,G).

% expression evaluation

% add/use exp evaluation for the corresponding point to the memory cache
add_cache_sum(P,FN,SUM), exp_point(E,P), eval(P,E,V,G),
    +memory_cache(FN,SUM)->eval(P,E,V,G).
use_cache_sum(FN,SUM), exp_point(E,P),
    memory_cache(FN,SUM)->eval(P,E,V,G),
    +omit_eval(P,E), +eval(P,E,V,G).

% integer constant expressions
(cil_exp_const(E,_);
 cil_exp_x_sizeof_alignof(E);
 cil_exp_binop(E,BOP,_,_,_), arith_op(BOP);
 cil_exp_unop(E,UOP,_,_), UOP\=u_lnot),
    cil_exp_x_intval(E,N), exp_tint(E,K),
    ?eval(P,E,_,_), ~omit_eval(P,E),
    (nrep_const_int(K,N,V);
     ~nrep_const_int(K,N,_), unconstrained_nrep(P,E,V)),
    #bool_g(true,G), +eval(P,E,nrep{V},G).

% CIL should be constant folding these &(0->field) but it's not.
% just get an unconstrained value
cil_exp_x_intval(MCE,0), cil_exp_cast(ME,MCE,_), cil_lval_mem(LV,ME,_),
    cil_exp_addr(AE,LV), cil_exp_cast(E,AE,_),
    ?eval(P,E,_,_), ~omit_eval(P,E),
    unconstrained_nrep(P,E,V), #bool_g(true,G), +eval(P,E,nrep{V},G).

% float constant expressions
cil_exp_const(E,C), cil_const_real(C,K,N),
    ?eval(P,E,_,_), ~omit_eval(P,E),
    (nrep_const_flt(K,N,V);
     ~nrep_const_flt(K,N,_), unconstrained_nrep(P,E,V)),
    #bool_g(true,G), +eval(P,E,nrep{V},G).

% string constant expressions
cil_const_str(C,STR), cil_exp_const(E,C), ?eval(P,E,_,_), ~omit_eval(P,E),
    #bool_g(true,G), +eval(P,E,trace{root{cstr{STR}}},G).

% evaluate lval expressions by getting val() for the referenced trace S.
% note that all variables are evaluated here, not just pointers.
% an 'abstract target' will then be generated for integer variables which
% are evaluated, i.e. int trace T will initially point to drf{T}
cil_exp_lval(E,LV), ?eval(P,E,_,_), ~omit_eval(P,E),
    lval(P,LV,S,SG), val(P,S,T,TG),
    #and(SG,TG,G), ~#bool_g(false,G), +eval(P,E,T,G).

% address-of lvalue expressions
cil_exp_addr(E,LV), ?eval(P,E,_,_), ~omit_eval(P,E),
    lval(P,LV,T,G), +eval(P,E,trace{T},G).

% evaluate unary arithmetic operations (-,~)
cil_exp_unop(E,OP,RE,_), OP\=u_lnot, ~cil_exp_x_intval(E,_),
    ?eval(P,E,_,_), ~omit_eval(P,E), eval_nrep(P,RE,RV,G),
    (nrep_unop(OP,RV,V);
     ~nrep_unop(OP,RV,_), unconstrained_nrep(P,E,V)),
    +eval(P,E,nrep{V},G).

% evaluate binary arithmetic operations (+,-,*,etc.)
arith_op(OP), cil_exp_binop(E,OP,LE,RE,_), ~cil_exp_x_intval(E,_),
    ?eval(P,E,_,_), ~omit_eval(P,E),
    eval_nrep(P,LE,LV,LG), eval_nrep(P,RE,RV,RG),
    #and(LG,RG,G), ~#bool_g(false,G),
    (nrep_binop(OP,LV,RV,V);
     ~nrep_binop(OP,LV,RV,_), unconstrained_nrep(P,E,V)),
    +eval(P,E,nrep{V},G).

% expression E is the sum of pointer LE and integer RE (scaled by sizeof(*LE)).
% fabricate a negation for b_minuspi
predicate exp_psum(E:c_exp,LE:c_exp,RE:c_exp) order [E,LE] [E,RE].
cil_exp_binop(E,b_pluspi,LE,RE,_), +exp_psum(E,LE,RE).
cil_exp_binop(E,b_minuspi,LE,RE,_), cil_make_exp(RE,"neg",NRE),
    exp_type(RE,RTYP), +cil_exp_unop(NRE,u_neg,RE,RTYP), +exp_psum(E,LE,NRE),
    cil_exp_x_intval(RE,N), int_neg(N,NN), +cil_exp_x_intval(NRE,NN).

% pointer arithmetic is handled only if generate_index_traces() is being used,
% otherwise ignored and preserving the targets of the LHS
~generate_index_traces(), exp_psum(E,LE,_), ?eval(P,E,_,_), ~omit_eval(P,E),
    eval(P,LE,T,G), +eval(P,E,T,G).
generate_index_traces(), exp_psum(E,LE,RE), ?eval(P,E,_,_), ~omit_eval(P,E),
    exp_type(E,TYP), convert_type(TYP,y_ptr{DY}),
    eval(P,LE,trace{T},LG), eval(P,RE,RI,RG),
    #and(LG,RG,G), ~#bool_g(false,G),
    trace_add_index(T,i_offset{DY,RI},NT),
    +eval(P,E,trace{NT},G).

% get an unconstrained value for arithmetic operations on pointers (minuspp)
pointer_int_op(OP), cil_exp_binop(E,OP,_,_,_),
    ?eval(P,E,_,_), ~omit_eval(P,E),
    unconstrained_nrep(P,E,V), #bool_g(true,G), +eval(P,E,nrep{V},G).

% add the cast for pointer to pointer cast expressions except when
% the target is not a trace. scalar to pointer casts will be handled by
% the scalar representation
cil_exp_cast(E,CE,TYP), exp_tptr(E), exp_tptr(CE),
    convert_type(TYP,y_ptr{DY}), ?eval(P,E,_,_), ~omit_eval(P,E),
    eval(P,CE,T,G), sum_body(SUM,P), trace_val_cast(SUM,T,DY,CT),
    +eval(P,E,CT,G).

% * -> int and int -> ptr casts. these are coercions and can change
% the sign or length of the value. model precisely unless ignore_int_casts()
~ignore_int_casts(), cil_exp_cast(E,CE,_), (~exp_tptr(E); ~exp_tptr(CE)),
    exp_type(E,TYP), type_bits(TYP,S,LEN),
    ?eval(P,E,_,_), ~omit_eval(P,E), eval_nrep(P,CE,CV,G),
    (nrep_cast(S,LEN,CV,V);
     ~nrep_cast(S,LEN,CV,_), unconstrained_nrep(P,E,V)),
    +eval(P,E,nrep{V},G).

% model casting behavior when casts among integers are being ignored
ignore_int_casts(), cil_exp_cast(E,CE,_), (~exp_tptr(E); ~exp_tptr(CE)),
    ?eval(P,E,_,_), ~omit_eval(P,E), eval(P,CE,T,G), +eval(P,E,T,G).

% evaluate boolean expressions by invoking beval and separately evaluating
% either to zero or one
nrep_const_int(iint,0,ZEROV), nrep_const_int(iint,1,ONEV),
    exp_boolean(E), ?eval(P,E,_,_), ~omit_eval(P,E),
    beval(P,E,TG,G), #not(TG,FG),
    #and(TG,G,TGG), #and(FG,G,FGG),
    +eval(P,E,nrep{ZEROV},FGG), +eval(P,E,nrep{ONEV},TGG).
(~nrep_const_int(iint,0,_); ~nrep_const_int(iint,1,_)),
    exp_boolean(E), ?eval(P,E,_,_), ~omit_eval(P,E),
    unconstrained_nrep(P,E,V), #bool_g(true,G), +eval(P,E,nrep{V},G).

% boolean expression evaluation

% evaluate comparisons directly. exp_boolean is defined for these
compare_op(OP), cil_exp_binop(E,OP,LE,RE,_),
    ?beval(P,E,_,_), ~omit_beval(P,E),
    eval_nrep(P,LE,LV,LG), eval_nrep(P,RE,RV,RG),
    #and(LG,RG,G), ~#bool_g(false,G),
    (nrep_cmp(OP,LV,RV,BG);
     ~nrep_cmp(OP,LV,RV,_), unconstrained_cond(P,E,BG)),
    +beval(P,E,BG,G).

% evaluate non-boolean expressions by invoking eval and comparing with zero
?beval(P,E,_,_), ~omit_beval(P,E), ~exp_boolean(E), eval(P,E,XV,G),
    trace_nrep_exp(P,E,XV,V),
    (nrep_nez(V,BG);
     ~nrep_nez(V,_), unconstrained_cond(P,E,BG)),
    +beval(P,E,BG,G).

% function/loop entry aliasing

% at entry to SUM, S may additionally point to T
predicate entry_points(in SUM:sum,in S:t_trace,T:t_trace).

% summary specific entry aliasing information
predicate inst_entry_points(SUM:sum,S:t_trace,T:t_trace).
cil_curfn(FN), sum_bound(SUM,_,_), ~omit_entry_alias_summary(SUM),
    sum_entry(FN,SUM)->spoints(S,T), +inst_entry_points(SUM,S,T).

% add entry_points for each inst_entry_points. watch for additional S->drf{S}
% edges which might be generated by the alias analysis
inst_entry_points(SUM,S,T), ~trace_simplify(SUM,drf{S},T),
    ~omit_entry_points(SUM,S,T), +entry_points(SUM,S,T).

% get entry points-to information from global and composite type summaries
entry_points(SUM,S,T) :- ~omit_entry_alias_summary(SUM),
    trace_root(S,glob{G}), sum_glob(G)->spoints(S,T),
    ~trace_simplify(s_func,drf{S},T),  % global spoints include S->drf{S} edges
    ~omit_entry_points(SUM,S,T).
entry_points(SUM,S,T) :- ~omit_entry_alias_summary(SUM),
    trace_sub(S,fld{STR,_,C},_), comp_to_relative(STR,S,RS),
    sum_comp(C)->spoints(RS,RT), comp_from_relative(STR,RT,T),
    ~omit_entry_points(SUM,S,T).

% instruction trace evaluation

% get call arguments which match the actual function type, if desired
predicate use_call_arg(in I:c_instr,in A:int).
matching_arg_inst_trace(), cil_instr_call(I,FNE),
    exp_type(FNE,FNTYP), cil_type_func_arg(FNTYP,A,_,_), +use_call_arg(I,A).
~matching_arg_inst_trace(), +use_call_arg(_,_).

% map arguments out of a call or asm
inst_trace(s_call{I},P,root{arg{A}},trace{T},G) :- use_call_arg(I,A),
    cil_instr_call_arg(I,A,E), cil_exp_lval(E,LV), lval(P,LV,T,G).
inst_trace(s_asm{I},P,root{asm_in{A}},trace{T},G) :-
    cil_instr_asm_in(I,A,_,_,E), cil_exp_lval(E,LV), lval(P,LV,T,G).
inst_trace(s_asm{I},P,root{asm_out{A}},trace{T},G) :-
    cil_instr_asm_out(I,A,_,_,LV), lval(P,LV,T,G).

% for arguments that are NOT l-values, we can only map out drf{arg{_}}
% through use of eval
inst_trace(s_call{I},P,drf{root{arg{A}}},T,G) :- use_call_arg(I,A),
    cil_instr_call_arg(I,A,E), ~cil_exp_lval(E,_), eval(P,E,T,G).
inst_trace(s_asm{I},P,drf{root{asm_in{A}}},T,G) :-
    cil_instr_asm_in(I,A,_,_,E), ~cil_exp_lval(E,_), eval(P,E,T,G).

% map the return value out of a call
inst_trace(s_call{I},P,root{return},trace{root{R}},G) :-
    callret(I,R), #bool_g(true,G).

% map the call target expression out of a call
inst_trace(s_call{I},P,root{call_target},T,G) :-
    cil_instr_call(I,E), eval(P,E,T,G).

% map arguments and locals out of a loop. just preserve the trace
inst_trace(s_loop{_},P,root{R},trace{root{R}},G) :-
    (R=arg{_}; R=local{_}), #bool_g(true,G).

% map globals and constant strings out of a call/loop. just preserve the trace
inst_trace(I,P,root{R},trace{root{R}},GG) :-
    (R=glob{_}; R=cstr{_}), #bool_g(true,GG).

% map drf{T} out of a call/loop. since drf{T} means the target at entry to the
% call/loop, evaluate T for its location and take its target at P.
% special case drf{root{return}} due to the implicit CIL call casting
inst_trace(I,P,drf{CPT},T,G) :- CPT\=root{return},
    inst_trace(I,P,CPT,trace{PT},PG), val(P,PT,T,TG),
    #and(PG,TG,G), ~#bool_g(false,G).
inst_trace(I,P,drf{root{return}},CDPT,G) :- sum_body(SUM,P),
    inst_trace(I,P,root{return},trace{PT},G),
    trace_simplify_index(SUM,drf{PT},DPT),
    (trace_type(I,drf{root{return}},Y), trace_val_cast(SUM,trace{DPT},Y,CDPT);
     ~trace_type(I,drf{root{return}},_), CDPT=trace{DPT}).

% map fields out of a call/loop, just map out the parent trace
inst_trace(I,P,fld{CT,F,C},trace{T},G) :-
    inst_trace(I,P,CT,trace{FT},G),
    sum_body(SUM,P), trace_simplify_index(SUM,fld{FT,F,C},T).
inst_trace(I,P,rfld{CT,F,C},trace{T},G) :-
    inst_trace(I,P,CT,trace{FT},G),
    sum_body(SUM,P), trace_simplify_index(SUM,rfld{FT,F,C},T).

% map out empty indexes
inst_trace(I,P,index{CT,[]},trace{NT},G) :-
    inst_trace(I,P,CT,trace{T},G),
    (T=index{_,_}, NT=T; T\=index{_,_}, NT=index{T,[]}).

% map out array indexes using inst_trace_val
inst_trace(I,P,index{CT,[i_offset{DY,CVI}|BI]},trace{NT},G) :-
    inst_trace(I,P,index{CT,BI},trace{T},TG), inst_trace_val(I,P,CVI,VI,VG),
    trace_add_index(T,i_offset{DY,VI},NT), #and(TG,VG,G), ~#bool_g(false,G).

% map out recursive indexes, failing on any encountered i_chain
inst_trace(I,P,index{CT,[i_next{RT}|BI]},trace{NT},G) :-
    inst_trace(I,P,index{CT,BI},trace{T},G), 
    trace_add_index(T,i_next{RT},NT).

% top-down instruction trace propagation

% to get the set of callee traces which *could* map to a given caller trace,
% we have to know which traces might not be in their usual invariant state.
% this includes all traces that have been previously written within the summary
% as well as any with extra entry aliasing. generate all inst_trace relevant
% to these accessed traces and store via rel_inst_trace

% T is a relevant trace accessed either at P or at an earlier point
% in the containing SUM
predicate rel_trace(P:pp,T:t_trace).

% add/use rel_inst_trace predicates from the memory cache summary
add_cache_sum(P,FN,SUM), rel_inst_trace(I,P,CT,T,G),
    +memory_cache(FN,SUM)->rel_inst_trace(I,P,CT,T,G).
use_cache_sum(FN,SUM), +no_rel_inst_trace(),
    memory_cache(FN,SUM)->rel_inst_trace(I,P,CT,T,G),
    +rel_inst_trace(I,P,CT,T,G).

% rel_trace for traces written directly or through an inner sum
~no_rel_inst_trace(), access(AP,T,write), trace_sub(drf{T},DT,_),
    pp_reach(AP,P), AP\=P, +rel_trace(P,DT).

% some interesting other operations
~no_rel_inst_trace(), cil_exp_addr(E,LV),
    ~(cil_lval_mem(LV,ME,_), cil_exp_cast(ME,MCE,_), cil_exp_x_intval(MCE,_)),
    lval_type(LV,TYP), ~cil_type_func(TYP,_,_),
    exp_point(E,AP), lval(AP,LV,T,_), trace_sub(drf{T},DT,_),
    +rel_trace(AP,DT), pp_reach(AP,P), +rel_trace(P,DT).

% rel_trace for entry points-to relations that apply over the entire SUM
~no_rel_inst_trace(), inst_entry_points(SUM,S,T),
    ~trace_simplify(SUM,drf{S},T),
    sum_body(SUM,P), trace_sub(drf{S},DS,_), +rel_trace(P,DS).

% now, for each call/loop site, crawl down through any relevant roots, staying
% within the rel_trace for points previous to that call/loop
predicate rel_get_trace(I:sum,P:pp,CT:t_trace).
~no_rel_inst_trace(), rel_get_trace(I,P,CT), inst_trace(I,P,CT,trace{T},G),
    +rel_inst_trace(I,P,CT,T,G).

% get the traces for any local/global/args accessed by loops/calls, and for
% all arguments on calls. for calls we need both __arg and *__arg to account
% for both non-lvalue arguments and for structs passed on the stack
~no_rel_inst_trace(), isum(P,_,I),
    rel_trace(P,root{R}), (I\=s_call{_}; R\=arg{_}),
    inst_may_access(I,root{R},read), +rel_get_trace(I,P,root{R}).
~no_rel_inst_trace(), icall(P,_,I), cil_instr_call_arg(I,AN,_), 
    +rel_get_trace(s_call{I},P,root{arg{AN}}),
    +rel_get_trace(s_call{I},P,drf{root{arg{AN}}}).

% arguments to assembly statements. input arguments may be passed either by
% value or by address, so just get the trace regardless of type.
% output arguments are always by address
~no_rel_inst_trace(), iasm(P,_,I), cil_instr_asm_in(I,AN,_,_,_),
    +rel_get_trace(s_asm{I},P,root{asm_in{AN}}),
    +rel_get_trace(s_asm{I},P,drf{root{asm_in{AN}}}).
~no_rel_inst_trace(), iasm(P,_,I), cil_instr_asm_out(I,AN,_,_,_),
    +rel_get_trace(s_asm{I},P,root{asm_out{AN}}).

% walk down dereferences and fields according to rel_trace.
% ignore indexes as we can't push arbitrary integer values top-down
~no_rel_inst_trace(), rel_inst_trace(I,P,CT,T,_), rel_trace(P,drf{T}),
    trace_simplify(I,drf{CT},DCT), +rel_get_trace(I,P,DCT).
~no_rel_inst_trace(), rel_inst_trace(I,P,CT,T,_), rel_trace(P,fld{T,F,C}),
    trace_simplify(I,fld{CT,F,C},FCT), +rel_get_trace(I,P,FCT).
~no_rel_inst_trace(), rel_inst_trace(I,P,CT,T,_), rel_trace(P,rfld{T,F,C}),
    trace_simplify(I,rfld{CT,F,C},FCT), +rel_get_trace(I,P,FCT).

% we need to extend rel_inst_trace to reflect assignments to structures
% themselves. rel_inst_trace will only be generated for the root structure,
% but we need to account for assignments to the individual fields
predicate base_td_inst_trace(in sum,in pp,in t_trace,out t_trace,out g_guard).
rel_inst_trace(I,P,CT,T,G), +base_td_inst_trace(I,P,T,CT,G).
base_td_inst_trace(I,P,drf{FT},drf{CFT},G) :-
    trace_fld_sub(FT,BT,RT), FT\=BT, rel_inst_trace(I,P,drf{CBT},drf{BT},_),
    trace_compose(I,CBT,RT,CFT), inst_trace(I,P,drf{CFT},trace{drf{FT}},G).

% finally, we can compute td_inst_trace by looking for any subtraces in
% base_td_inst_trace, which will reflect all trace modifications performed
% by the caller. look only for the largest subtrace in rel_inst_trace
% to avoid overapproximating the guard
td_inst_trace(I,P,T,CT,G) :- base_td_inst_trace(I,P,T,CT,G).
td_inst_trace(I,P,T,CT,G) :-
    (T=drf{BT}, td_inst_trace(I,P,BT,CBT,G0), val(P,BT,trace{drf{BT}},G1),
         #and(G0,G1,G), NCT=drf{CBT};
     T=fld{BT,F,C}, td_inst_trace(I,P,BT,CBT,G), NCT=fld{CBT,F,C};
     T=rfld{BT,F,C}, td_inst_trace(I,P,BT,CBT,G), NCT=rfld{CBT,F,C};
     T=index{BT,[]}, td_inst_trace(I,P,BT,CBT,G),
         (T=index{_,_}, NCT=CBT; T\=index{_,_}, NCT=index{CBT,[]});
     T=index{BT,[i_offset{Y,VI}|RI]}, td_inst_trace(I,P,index{BT,RI},CBT,G0),
         td_inst_trace_val(I,P,VI,CVI,G1), #and(G0,G1,G),
         trace_add_index(CBT,i_offset{Y,CVI},NCT);
     T=index{BT,[i_next{RT}|RI]}, td_inst_trace(I,P,index{BT,RI},CBT,G),
         trace_add_index(CBT,i_next{RT},NCT)),
    trace_simplify(I,NCT,CT).

% also look to see if the trace maps back to itself via inst_trace.
% this covers cases where the trace was left in its invariant state
% by the caller
td_inst_trace(I,P,T,T,G) :-
    (~trace_root(T,arg{_}); I=s_loop{_}), inst_trace(I,P,T,trace{T},G).

% val() merging

% adding will merge G into the condition under which S points to T at P
predicate vmerge(in P:pp,in S:t_trace,T:t_trace_val,G:g_guard).
~disable_val(), ?val(P,S,_,_), vmerge(P,S,T,_),
    \/vmerge(P,S,T,G):#or_all(G,MG), #simplify(MG,NMG),
    ~#bool_g(false,NMG), +val(P,S,T,NMG).

% initial value information

% use entry_bit() to compute the initial targets and (disjoint) guards for S.
% TGTS includes all traces besides drf{S} that S might point to, and DTGTS
% includes drf{S} as well (with all leftover conditions as the guard)
predicate split_entry_guard(in P:pp,in S:t_trace,
                            in TGTS:list[t_trace],in PG:g_guard,
                            DTGTS:list[t_pair[t_trace,g_guard]]).
?split_entry_guard(P,S,[],PG,_), sum_body(SUM,P),
    trace_simplify_index(SUM,drf{S},T),
    +split_entry_guard(P,S,[],PG,[pair{T,PG}]).
?split_entry_guard(P,S,[T|TAIL],PG,_), entry_bit(P,S,T,BG),
    #and(BG,PG,CPG), #not(BG,NBG), #and(NBG,PG,NPG),
    split_entry_guard(P,S,TAIL,NPG,DTAIL),
    +split_entry_guard(P,S,[T|TAIL],PG,[pair{T,CPG}|DTAIL]).

% resolve val() at summary entry points by using entry_points,
% getting disjoint guards
~no_entry_aliasing(), sum_bound(SUM,P,_), ?vmerge(P,S,_,_),
    \/entry_points(SUM,S,XT):list_all(XT,TGTS),
    #bool_g(true,TG), split_entry_guard(P,S,TGTS,TG,DTGTS),
    list_mem(DTGTS,pair{T,G}), +vmerge(P,S,trace{T},G).
no_entry_aliasing(), sum_bound(SUM,P,_), ?vmerge(P,S,_,_),
    trace_simplify_index(SUM,drf{S},T),
    #bool_g(true,G), +vmerge(P,S,trace{T},G).

% transfer functions

% assigning to S implicitly casts T to CT. CIL introduces explicit casts for
% everything but function returns *grumble*
predicate sassign_cast(in SUM:sum,in S:t_trace,in T:t_trace_val,
                       CT:t_trace_val).
?sassign_cast(SUM,S,T,_), trace_type(SUM,S,y_ptr{Y}),
    trace_val_cast(SUM,T,Y,CT), +sassign_cast(SUM,S,T,CT).
?sassign_cast(SUM,S,T,_), ~trace_type(SUM,S,y_ptr{_}),
    +sassign_cast(SUM,S,T,T).

% the assignment at P of T to S when BG holds also assigns TF to SF of S
% when G holds. this covers both the direct assignment T -> S as well as any
% indirect structure field assignments resulting from T -> S
predicate sassign(in P:pp,in S:t_trace,in T:t_trace_val,in BG:g_guard,
                  in SF:t_trace,TF:t_trace_val,G:g_guard).
?sassign(P,S,T,G,S,_,_), sum_body(SUM,P), sassign_cast(SUM,S,T,CT),
    +sassign(P,S,T,G,S,CT,G).
?sassign(P,S,trace{drf{T}},BG,SF,_,_), trace_fld_sub(SF,S,SR), SF\=S,
    sum_body(SUM,P), trace_compose(SUM,T,SR,PTF), val(P,PTF,TF,TG),
    #and(BG,TG,G), +sassign(P,S,trace{drf{T}},BG,SF,TF,G).

% find where traces are directly read from
cil_exp_lval(E,LV), exp_point(E,P), lval(P,LV,S,_), +access(P,S,read).

% S is written with T at point P. mark S as written, as well as any field F
% of S that is written to T
predicate sassign_write(P:pp,S:t_trace,T:t_trace_val,G:g_guard).
sassign_write(P,S,_,_), +access(P,S,write).
sassign_write(P,S,trace{drf{T}},_), access(PP,TF,write), pp_reach(PP,P),
    trace_fld_sub(TF,T,TR),
    sum_body(SUM,P), trace_compose(SUM,S,TR,SF), +access(P,SF,write).

% if S is assigned to by a set, merge the targets of the RHS with its targets
% after the set
iset(P0,P1,I), cil_instr_set(I,LV,E), lval(P0,LV,S,LG), eval(P0,E,T,RG),
    #and(LG,RG,BG), ~#bool_g(false,BG), +sassign_write(P0,S,T,BG),
    ?vmerge(P1,SF,_,_), sassign(P0,S,T,BG,SF,TF,G),
    eguard(P0,P1,G,EG), +vmerge(P1,SF,TF,EG).

% if X is NOT assigned to by a set, nor is it a subfield of the structure
% assigned to by the set, merge its old targets with its targets after the set
iset(P0,P1,I), cil_instr_set(I,LV,_),
    lval(P0,LV,OS,LG), ?vmerge(P1,S,_,_), ~trace_fld_sub(S,OS,_),
    val(P0,S,T,RG), #and(LG,RG,G),
    eguard(P0,P1,G,EG), +vmerge(P1,S,T,EG).

% if X is soft, merge its old targets with its targets after the set
~generate_index_traces(), iset(P0,P1,_), sum_body(SUM,P0),
    ?vmerge(P1,S,_,_), trace_soft(SUM,S,_),
    val(P0,S,T,G), eguard(P0,P1,G,EG), +vmerge(P1,S,T,EG).

% summary transfer function, use inst_transfer
isum(P0,P1,_), ?vmerge(P1,S,_,_), inst_transfer(P0,S,T,G),
    eguard(P0,P1,G,EG), +vmerge(P1,S,T,EG).

% branches leave all values alone
branch(P,P0,_,_), ?vmerge(P0,S,_,_), val(P,S,T,G),
    eguard(P,P0,G,EG), +vmerge(P0,S,T,EG).
branch(P,_,P1,_), ?vmerge(P1,S,_,_), val(P,S,T,G),
    eguard(P,P1,G,EG), +vmerge(P1,S,T,EG).

% summary information

% add/use inst_usemod and inst_exit_points to the memory cache
add_cache_sum(P,FN,SUM), isum(P,_,I), inst_exit_points(I,CS,CT),
    +memory_cache(FN,SUM)->inst_exit_points(I,CS,CT).
add_cache_sum(P,FN,SUM), isum(P,_,I), inst_usemod(I,CT,Y),
    +memory_cache(FN,SUM)->inst_usemod(I,CT,Y).
add_cache_sum(P,FN,SUM), isum(P,_,I), inst_anyuse(I),
    +memory_cache(FN,SUM)->inst_anyuse(I).
use_cache_sum(FN,SUM), memory_cache(FN,SUM)->inst_exit_points(I,CS,CT),
    +inst_exit_points(I,CS,CT).
use_cache_sum(FN,SUM), memory_cache(FN,SUM)->inst_usemod(I,CT,Y),
    +inst_usemod(I,CT,Y).
use_cache_sum(FN,SUM), memory_cache(FN,SUM)->inst_anyuse(I),
    +inst_anyuse(I).
use_cache_sum(_,_), +omit_exit_alias_summary(_).

% populate inst_usemod and inst_exit_points according to callee summaries
isum_target(I,FN,SUM,_), ~omit_exit_alias_summary(I),
    sum_usemod(FN,SUM)->stuse(CT,Y),
    ~(inst_anyuse(I), trace_root(CT,glob{_})), +inst_usemod(I,CT,Y).
isum_target(I,FN,SUM,_), ~omit_exit_alias_summary(I),
    sum_usemod(FN,SUM)->sanyuse(), +inst_anyuse(I).
isum_target(I,FN,SUM,_), ~omit_exit_alias_summary(I),
    sum_exit(FN,SUM)->spoints(CS,CT),
    ~omit_exit_points(I,CS,CT), +inst_exit_points(I,CS,CT).

% use scwrite to filter out overapproximated field writes in inst_may_access
predicate no_field_access(in SUM:sum,in T:t_trace,in Y:access_type).
no_field_access(SUM,T,Y) :- (Y=write; Y=deepwrite),
    trace_sub(T,drf{fld{_,F,C}},_), ~sum_usemod_comp(C)->scwrite(F).

% compute traces that might be accessed by a summary from usemod information
inst_usemod(SUM,T,Y), +inst_may_access(SUM,T,Y).
inst_usemod(SUM,T,Y), (Y=deepread; Y=deepwrite), +inst_may_access(SUM,T,read).
inst_may_access(SUM,T,Y) :- trace_sub(T,ST,_), T\=ST,
    inst_usemod(SUM,ST,DY),
    (DY=deepread, Y=read; DY=deepwrite, Y=write; DY\=read, DY\=write, Y=DY),
    ~no_field_access(SUM,T,Y).
inst_usemod(SUM,ST,DY), trace_sub(ST,T,_), ST\=T,
    (Y=read; DY=read, Y=deepread; DY=write, Y=deepwrite; DY\=read, DY\=write, Y=DY),
    ~no_field_access(SUM,T,Y), +inst_may_access(SUM,T,Y).
inst_may_access(SUM,T,Y) :- inst_anyuse(SUM),
    trace_root(T,glob{G}), sum_usemod_glob(G)->sganyuse(Y),
    ~no_field_access(SUM,T,Y).

% default behavior used for iasms: input args are read, output args are written
inst_may_access(s_asm{I},T,read) :- trace_root(T,asm_in{_}).
inst_may_access(s_asm{I},T,write) :- trace_root(T,asm_out{_}).

% summary transfer function

% introduce new fresh traces based on inst_unified if the caller does not
% have an existing representation for the trace, i.e. the dereference of an
% integer value:
% foo(int **x) { *x = malloc(); }
% bar() { int *x = 0; foo(&x); }
%isum(P0,P1,SUM), ~no_exit_aliasing(SUM,P0),
%    rel_get_trace(SUM,P0,drf{CT}), rel_inst_trace(SUM,P0,CT,T,TG),
%    isum_target(SUM,CFN,CSUM,direct), sum_usemod(CFN,CSUM)->stalloc(CT),
%    val(P0,T,nrep{_},NG), #and(TG,NG,G),
%    +inst_trace(SUM,P0,drf{CT},trace{drf{T}},G), ?vmerge(P1,T,_,_),
%    eguard(P0,P1,G,EG), +vmerge(P1,T,trace{drf{T}},EG).

% all-in-one fuzzing. S is written with T by the isum at P. T is either the
% target given by a pointer side effect on the summary, or is the previous
% value of S. NT is the final result of the write
predicate inst_write_val(in P:pp,in CT:t_trace,in S:t_trace,in T:t_trace_val,
                         NT:t_trace_val).

% for pointers to array indexes, add an unconstrained index
generate_index_traces(), ?inst_write_val(P,CT,S,trace{T},_), sum_body(SUM,P),
    isum(P,_,CSUM), trace_soft(CSUM,CT,SFT),
    (SFT=array; SFT=ptarray), trace_type(SUM,S,y_ptr{DY}),
    trace_strip_index(S,BS), trace_strip_index(T,BT),
    inst_write_array(P,BS,BT,AI),
    trace_add_index(T,i_offset{DY,AI},NT),
    +inst_write_val(P,CT,S,trace{T},trace{NT}).

% for pointers to recursive structures, add an unconstrained access chain
generate_index_traces(), ?inst_write_val(P,CT,S,trace{T},_),
    isum(P,_,CSUM), trace_soft(CSUM,CT,recurse),
    trace_strip_index(S,BS), trace_strip_index(T,BT),
    trace_add_index(T,i_chain{P,BS,BT},NT),
    +inst_write_val(P,CT,S,trace{T},trace{NT}).

generate_index_traces(), ?inst_write_val(P,CT,S,trace{T},_), sum_body(SUM,P),
    isum(P,_,CSUM), trace_soft(CSUM,CT,softsub),
    trace_sub(CT,SCT,RT), trace_soft(CSUM,SCT,Y), Y\=softsub,
    ~(trace_sub(SCT,XSCT,_), SCT\=XSCT, trace_soft(CSUM,XSCT,Y), Y\=softsub),
    trace_sub(T,ST,RT), inst_write_val(P,SCT,S,trace{ST},trace{NST}),
    trace_compose(SUM,NST,RT,NT), +inst_write_val(P,CT,S,trace{T},trace{NT}).

% for integers, get an unconstrained value
?inst_write_val(P,CT,S,T,_), sum_body(SUM,P), trace_type(SUM,S,Y),
    (Y=y_int{_}; Y=y_enum{_}; Y=y_flt{_}),
    inst_write_int(P,S,NT), +inst_write_val(P,CT,S,T,NT).

% for other traces, just preserve the original value
predicate inst_write_any(in P:pp,in CT:t_trace,in S:t_trace,in T:t_trace_val,
                         NT:t_trace_val).
?inst_write_any(P,CT,S,T,_), inst_write_val(P,CT,S,T,NT),
    +inst_write_any(P,CT,S,T,NT).
?inst_write_any(P,CT,S,T,_), ~inst_write_val(P,CT,S,T,_),
    +inst_write_any(P,CT,S,T,T).

% SUM at P may write a new value to S if G holds. use per-trace usemod
% information if available
predicate inst_may_write(in SUM:sum,in P:pp,in S:t_trace,CS:t_trace,G:g_guard).
?inst_may_write(SUM,P,S,_,_), ~no_inst_may_write(SUM,P,S),
    trace_strip_index(S,NS), td_inst_trace(SUM,P,NS,CS,G),
    inst_may_access(SUM,CS,write), +inst_may_write(SUM,P,S,CS,G).

% isum transfer preserves all targets when the inst_transfer_necessary conds
% are met. get the conditions under which a write occurs and inst_write_any
isum(P,_,SUM), ?inst_transfer(P,S,_,_), val(P,S,T,LG),
    \/inst_transfer_necessary(SUM,P,S,TG):#and_all(TG,MTG), #and(LG,MTG,LMTG),
    \/inst_may_write(SUM,P,S,_,WG):#or_all(WG,MWG), #not(MWG,NMWG),
    #and(LMTG,NMWG,NVWG), +inst_transfer(P,S,T,NVWG),
    inst_may_write(SUM,P,S,CS,CWG), trace_simplify(SUM,drf{CS},DCS),
    inst_write_any(P,DCS,S,T,NT),
    #and(LMTG,CWG,VWG), +inst_transfer(P,S,NT,VWG).

predicate split_transfer_necessary(SUM:sum,P:pp,S:t_trace,G:g_guard).
split_transfer_necessary(SUM,P,S,G), ?inst_transfer_necessary(SUM,P,SF,_),
    trace_fld_sub(SF,S,_), +inst_transfer_necessary(SUM,P,SF,G).

predicate split_transfer_write(P:pp,S:t_trace,T:t_trace_val,CT:t_trace,G:g_guard).
split_transfer_write(P,S,T,CT,G), +sassign_write(P,S,T,G),
    ?inst_transfer(P,SF,_,_), sassign(P,S,T,G,SF,TF,NG),
    inst_write_any(P,CT,SF,TF,NTF), +inst_transfer(P,SF,NTF,NG).

% add/use split_transfer results to the memory_cache
add_cache_sum(P,FN,SUM), split_transfer_necessary(I,P,S,G),
    +memory_cache(FN,SUM)->split_transfer_necessary(I,P,S,G).
add_cache_sum(P,FN,SUM), split_transfer_write(P,S,T,CT,G),
    +memory_cache(FN,SUM)->split_transfer_write(P,S,T,CT,G).
use_cache_sum(FN,SUM), memory_cache(FN,SUM)->split_transfer_necessary(I,P,S,G),
    +split_transfer_necessary(I,P,S,G).
use_cache_sum(FN,SUM), memory_cache(FN,SUM)->split_transfer_write(P,S,T,CT,G),
    +split_transfer_write(P,S,T,CT,G).
use_cache_sum(_,_), +no_exit_aliasing(_,_).

% compute side effects for each icall/iloop, mapping back sum_exit to the
% caller and updating the value afterwards. make fresh bits to distinguish
% between different side effects and the default targets-preserved behavior
predicate split_exit(SUM:sum,P:pp,CS:t_trace,
                     TGTS:list[t_trace],PG:g_guard).
split_exit(SUM,P,CS,[],PG),
    inst_trace(SUM,P,CS,trace{S},SG),
    #not(SG,NSG), #or(NSG,PG,G), +split_transfer_necessary(SUM,P,S,G).
split_exit(SUM,P,CS,[CT|TAIL],PG), exit_bit(SUM,P,CS,CT,BG),
    #and(BG,PG,CPG), #not(BG,NBG), #and(NBG,PG,NPG),
    +split_exit(SUM,P,CS,TAIL,NPG),
    inst_trace(SUM,P,CS,trace{S},SG), inst_trace(SUM,P,CT,T,TG),
    #and(SG,TG,MG), #and(MG,CPG,XG), +split_transfer_write(P,S,T,CT,XG).

isum(P,_,SUM), ~no_exit_aliasing(SUM,P),
    inst_exit_points(SUM,CS,_), \/inst_exit_points(SUM,CS,CT):list_all(CT,TGT),
    #bool_g(true,G), +split_exit(SUM,P,CS,TGT,G).

% if a function returns an alias for earlier data, kill the default
% return value by setting 'false' as a necessary condition.
% TODO: this leaves the guards incomplete for the return value
icall(P,_,I), ~no_exit_aliasing(s_call{I},P),
    inst_exit_points(s_call{I},root{return},_), callret(I,S),
    #bool_g(false,FG), +split_transfer_necessary(s_call{I},P,root{S},FG).

% index stringification

predicate index_list_string(in RL:t_trace_index,list[string]).
+index_list_string([],[]).
index_list_string([i_offset{_,IV}|TAIL],[IS|STAIL]) :-
    index_list_string(TAIL,STAIL), trace_nrep(IV,IVN), nrep_string(IVN,IVS),
    IS = "["^IVS^"]".
index_list_string([i_next{RT}|TAIL],[IS|STAIL]) :-
    index_list_string(TAIL,STAIL), trace_string(RT,IS).
index_list_string([i_chain{P,S,T}|TAIL],[IS|STAIL]) :-
    index_list_string(TAIL,STAIL),
    (isum(P,_,I), dstring_sum(I,IIS);
     ~isum(P,_,_), IIS="call:unknown"),
    trace_string(S,SS), trace_string(T,TS),
    IS = "chain("^IIS^","^SS^","^TS^")".

trace_string(index{T,[i_offset{_,IV}]},S) :-
    trace_string(T,TS), trace_nrep(IV,IVN), nrep_string(IVN,IS),
    S = TS^"["^IS^"]".
trace_string(index{T,I},S) :- I\=[i_offset{_,_}],
    trace_string(T,TS), index_list_string(I,SLIST),
    str_cat_list_sep(SLIST,",",IS),
    S = TS^"{"^IS^"}".

dstring_trace(SUM,index{drf{T},[i_offset{_,IV}]},S) :-
    dstring_trace(SUM,T,TS), trace_nrep(IV,IVN), dstring_nrep(SUM,IVN,IVS),
    S = TS^"["^IVS^"]".
dstring_trace(SUM,index{T,[i_offset{_,IV}]},S) :- T\=drf{_},
    dstring_trace(SUM,T,TS), trace_nrep(IV,IVN), dstring_nrep(SUM,IVN,IVS),
    S = TS^"["^IVS^"]".
dstring_trace(SUM,index{T,I},S) :- I\=[i_offset{_,_}],
    dstring_trace(SUM,T,TS), index_list_string(I,SLIST),
    str_cat_list_sep(SLIST,",",IS),
    S = TS^"{"^IS^"}".

% baked in

import "memorybaked.clp".

% checks

%?lval(P,LV,_,_), ~lval(P,LV,_,_),
%    cil_curfn(FN), point_location(P,_,LINE),
%    lval_string(LV,S), +warning("Could not evaluate LV",FN,LINE,S).
%?eval(P,E,_,_), ~eval(P,E,_,_),
%    cil_curfn(FN), point_location(P,_,LINE),
%    exp_string(E,S), +warning("Could not evaluate EXP",FN,LINE,S).
%?beval(P,E,_,_), ~beval(P,E,_,_),
%    cil_curfn(FN), point_location(P,_,LINE),
%    exp_string(E,S), +warning("Could not evaluate BEXP",FN,LINE,S).
